{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c6a83c-4360-4ae1-9c11-08ca41e15fc8",
   "metadata": {},
   "source": [
    "# 2 - Serve Local LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b3a2c-9b2d-4ec3-87d1-5d0a53b4e5f6",
   "metadata": {},
   "source": [
    "Quick sanity check on the current environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "05f10044-a5e4-4848-8fa0-d27d5defce9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ian/miniforge3/envs/tutorial-local-llm/bin/python'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c2d1ccb-f3dd-4234-a7f8-eae2f069e3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.12.12 | packaged by conda-forge | (main, Oct 22 2025, 23:34:53) [Clang 19.1.7 ]'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bf2ef-ab9d-4e4c-a5ca-c69ca157698a",
   "metadata": {},
   "source": [
    "## 2.1 Check Ollama available models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6570b-26ef-4c68-979e-a81d27dcaee4",
   "metadata": {},
   "source": [
    "If you did the setup correctly (see `README.md` in the repo root) then you should see at least a few models already available locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ded2a46-3488-4939-a2dd-17b63932f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc8939-9153-4e86-88dd-b4893d8b158c",
   "metadata": {},
   "source": [
    "The model details are a bit buried in the return object from the `.list()` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2d993c5-f454-47e1-9868-8f6a542d1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(ollama.list())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ca52be5-bc18-4b75-aebf-e425ff397379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ollama models (local):\n",
      "\n",
      "qwen3:4b                      \tqwen3\t4.0B\t  2497 MB\tQ4_K_M\tgguf\n",
      "sematre/orpheus:ft-en-3b-q2_k \tllama\t3.8B\t  1595 MB\tQ2_K\tgguf\n",
      "sematre/orpheus:ft-en-3b      \tllama\t3.8B\t  4028 MB\tQ8_0\tgguf\n",
      "llama3.2-vision:latest        \tmllama\t10.7B\t  7816 MB\tQ4_K_M\tgguf\n",
      "tinyllama:1.1b                \tllama\t1B\t   637 MB\tQ4_0\tgguf\n",
      "gemma2:2b                     \tgemma2\t2.6B\t  1629 MB\tQ4_0\tgguf\n",
      "glm-4.6:cloud                 \tglm4\t355B\t     0 MB\tFP8\t\n",
      "codestral:latest              \tllama\t22.2B\t 12569 MB\tQ4_0\tgguf\n",
      "mathstral:latest              \tllama\t7.2B\t  4113 MB\tQ4_0\tgguf\n",
      "mistral:7b                    \tllama\t7.2B\t  4372 MB\tQ4_K_M\tgguf\n",
      "falcon3:1b                    \tllama\t1.7B\t  1778 MB\tQ8_0\tgguf\n",
      "gemma3:270m                   \tgemma3\t268.10M\t   291 MB\tQ8_0\tgguf\n",
      "qwen:latest                   \tqwen2\t4B\t  2330 MB\tQ4_0\tgguf\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nOllama models (local):\\n')\n",
    "for m in models:\n",
    "    print(f'{m.model:<30}\\t'+\n",
    "          f'{m.details.family}\\t'+\n",
    "          f'{m.details.parameter_size}\\t'+\n",
    "          f'{int(m.size/(1e6)):>6} MB\\t'+\n",
    "          f'{m.details.quantization_level}\\t'+\n",
    "          f'{m.details.format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014f780-b003-4f6d-bb5b-b539d988a757",
   "metadata": {},
   "source": [
    "## 2.2 Connect to your Ollama local LLM server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72902ab5-c8dd-462c-ba74-bc995ff0b7af",
   "metadata": {},
   "source": [
    "Now make a one-shot request to the smallest LLM, `gemma3:270m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d8dd465-ceac-41f7-aea1-d2afd4bd8efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 ms, sys: 4.33 ms, total: 6.05 ms\n",
      "Wall time: 995 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = ollama.generate(model='gemma3:270m', prompt='Tell me a one paragraph story about a chicken')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ef407-3967-44f1-97f5-ee40589266d0",
   "metadata": {},
   "source": [
    "If that didn't work for you, make sure Ollama is running.  There are two ways to do this:\n",
    "\n",
    "* Desktop native app -- search *Start* (Windows) or *CMD-SPACE* (MacOS) for \"Ollama\" and make sure it is running\n",
    "* From the command line:\n",
    "\n",
    "```bash\n",
    "ollama start\n",
    "```\n",
    "\n",
    "The latter has the advantage that you can see incoming requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6174c583-5375-4ee8-a115-0349fcd21fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A lonely chicken, with a feathered heart, found its way to a cozy coop. Its journey was filled with foraging for food, cleaning the coop, and protecting its young from predators. Despite the hardships, the chicken persevered, its strong legs and unwavering spirit proving its resilience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dab7ca-034d-4c1f-872a-9d47c282edb3",
   "metadata": {},
   "source": [
    "### EXERCISE: Experiment with different models & one-shot queries\n",
    "*(5 minutes)*\n",
    "\n",
    "Notes:\n",
    "* Start with the smallest model and then increment in parameter size\n",
    "* Use *\"Task Manager\"* (Windows) or *\"Activity Monitor\"* (MacOS) to see how much CPU and RAM Ollama is using\n",
    "* Try the same prompt more than once with the same model to get a sense of intra-model variability\n",
    "* Try the same prompt more than once with different models to get a sense of inter-model variability\n",
    "\n",
    "If the model outputs Markdown, you can display it in a Jupyter notebook with:\n",
    "\n",
    "```python\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response.response))\n",
    "```\n",
    "\n",
    "Outside of Jupyter notebook you'll need something like [`python-markdown`](https://python-markdown.github.io/) to convert Markdown text to HTML.\n",
    "\n",
    "There is a helper function `printmd()` below that you can use to directly display generated Markdown in Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "080e689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.86 ms, sys: 18.8 ms, total: 25.7 ms\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = ollama.generate(model='qwen3:4b', prompt='What are some of the current geo-political issues?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0dba05c4-2d39-4a3a-94c7-3bc666f7c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "def printmd(text:str) -> None:\n",
    "    ''' Jupyter-only print function for markdown text '''\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a124e97f-d870-477e-b962-1c33ef9dbe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some of the most **significant, active, and interconnected geo-political issues** as of late 2023/early 2024, based on current global events, expert analysis, and real-world impact. I've prioritized issues with high stakes, ongoing volatility, and direct relevance to global stability:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. **The Russia-Ukraine War (Ongoing)**  \n",
       "   - **Why it matters**: The largest active conflict since WWII, with profound implications for global security, energy, food, and finance.  \n",
       "   - **Current dynamics**:  \n",
       "     - Russia's continued invasion (2022‚Äìpresent), including attacks on infrastructure in Ukraine.  \n",
       "     - Western sanctions on Russia (e.g., oil/gas price caps, banking isolation) and Russia's response (e.g., energy exports to China, hybrid warfare).  \n",
       "     - Ukraine's push for NATO integration and European security reform.  \n",
       "     - **Humanitarian impact**: Over 10 million displaced, massive food insecurity in Ukraine, and global food price volatility.  \n",
       "   - *Why it's critical*: A direct test of Western unity, energy security, and the future of European stability.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **The Israel-Hamas War (Ongoing)**  \n",
       "   - **Why it matters**: A rapidly escalating conflict with global implications for Middle Eastern security, refugees, and regional power dynamics.  \n",
       "   - **Current dynamics**:  \n",
       "     - Hamas' October 7, 2023 attack on Israel (resulting in ~1,200+ deaths) and Israel's military response in Gaza.  \n",
       "     - **Gaza humanitarian crisis**: Over 40,000+ deaths, widespread destruction, and severe shortages of water, food, and medical supplies.  \n",
       "     - Regional tensions: Escalating conflicts in Lebanon (Hezbollah vs. Israel), Jordan, and the broader Middle East.  \n",
       "     - U.S. mediation efforts and global calls for ceasefire.  \n",
       "   - *Why it's critical*: Threatens regional stability, displaces millions, and risks a broader conflict in the Middle East.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **U.S.-China Strategic Competition (Intensifying)**  \n",
       "   - **Why it matters**: The defining global power struggle of the 21st century, impacting technology, trade, climate, and security.  \n",
       "   - **Current dynamics**:  \n",
       "     - **Tech war**: U.S. restrictions on Chinese tech (e.g., semiconductor exports, AI), China's push for \"self-reliance\" (e.g., semiconductor production).  \n",
       "     - **Trade tensions**: Tariffs, supply chain shifts (e.g., U.S. moving manufacturing to Asia), and China's economic slowdown.  \n",
       "     - **Military competition**: U.S. naval presence in the South China Sea, China's assertive claims in the South China Sea and Taiwan Strait.  \n",
       "     - **Climate & security**: Both nations competing for influence in climate policy and global security frameworks (e.g., nuclear proliferation).  \n",
       "   - *Why it's critical*: Could reshape global trade, technology governance, and even climate action.\n",
       "\n",
       "---\n",
       "\n",
       "### 4. **Climate Change & Geopolitical Instability**  \n",
       "   - **Why it matters**: Climate disasters are increasingly triggering migration, resource conflicts, and political upheaval.  \n",
       "   - **Current dynamics**:  \n",
       "     - **Extreme weather**: Record floods in Pakistan (2022), wildfires in Canada (2023), and heatwaves in Europe (2023‚Äì2024).  \n",
       "     - **Resource conflicts**: Water scarcity in the Middle East (e.g., Jordan), competition over Arctic resources (oil/gas), and food security crises (e.g., Ukraine war disrupting grain exports).  \n",
       "     - **Migration**: Climate-driven displacement (e.g., 30+ million displaced by climate disasters since 2015) straining regions like Europe and Africa.  \n",
       "     - **Policy gaps**: Failure to implement the Paris Agreement effectively, with major economies lagging on emissions targets.  \n",
       "   - *Why it's critical*: Climate change is now a **direct driver** of conflict, migration, and economic instability‚Äîmaking it inseparable from geo-politics.\n",
       "\n",
       "---\n",
       "\n",
       "### 5. **Global Economic Instability & Debt Crises**  \n",
       "   - **Why it matters**: Economic fragility threatens global growth, inequality, and financial systems.  \n",
       "   - **Current dynamics**:  \n",
       "     - **Debt crises**: High debt levels in developing nations (e.g., Argentina, Ghana), exacerbated by climate disasters and the Ukraine war.  \n",
       "     - **Inflation & recessions**: Persistent inflation in the U.S. (2022‚Äì2024), China's economic slowdown, and supply chain disruptions.  \n",
       "     - **Currency wars**: Competition over reserves (e.g., U.S. dollar dominance vs. China's push for digital currencies).  \n",
       "     - **Food/fuel prices**: Ukraine war disrupting grain exports (30% of global wheat), driving up food costs globally.  \n",
       "   - *Why it's critical*: Economic instability fuels social unrest, migration, and geopolitical realignments (e.g., \"de-dollarization\" movements).\n",
       "\n",
       "---\n",
       "\n",
       "### 6. **The Rise of Non-State Actors & Hybrid Warfare**  \n",
       "   - **Why it matters**: Groups like Hezbollah, Hamas, and terrorist networks are increasingly pivotal in conflicts.  \n",
       "   - **Current dynamics**:  \n",
       "     - **Hybrid warfare**: Russia's use of disinformation, cyberattacks, and proxy forces in Ukraine.  \n",
       "     - **Regional conflicts**: Somalia (Al-Shabaab), Sudan (civil war), and Afghanistan (Taliban's return).  \n",
       "     - **Tech-enabled warfare**: AI for targeting, drone strikes, and disinformation campaigns.  \n",
       "   - *Why it's critical*: Weakens state-centric security models and shifts power to decentralized actors.\n",
       "\n",
       "---\n",
       "\n",
       "### Why These Issues Matter *Together*  \n",
       "These problems are **interconnected**, not isolated:  \n",
       "- The Ukraine war ‚Üí food price spikes ‚Üí global inflation ‚Üí economic instability.  \n",
       "- U.S.-China tech competition ‚Üí supply chain shifts ‚Üí climate tech access ‚Üí economic inequality.  \n",
       "- Climate disasters ‚Üí migration ‚Üí regional conflicts (e.g., Africa, Middle East) ‚Üí resource wars.  \n",
       "\n",
       "> üí° **Key takeaway for the user**: The most urgent geo-political challenges today are **not just about \"who wins\"**, but about **how the world adapts to interlinked crises** (war, climate, economics). Solutions require cooperation‚Äînot competition‚Äîbetween nations, regions, and even within societies.\n",
       "\n",
       "---\n",
       "\n",
       "### Resources for Deeper Understanding:\n",
       "- **For real-time updates**: [Reuters Geo-Politics](https://www.reuters.com/world/geopolitics), [Bloomberg Geo-Politics](https://www.bloomberg.com/news/topics/geopolitics)  \n",
       "- **For analysis**: *The Economist*‚Äôs \"Geo-Political Hotspots\" section, [CIA World Factbook](https://www.cia.gov/the-world-factbook/) (for country-specific context).\n",
       "\n",
       "If you're interested in a specific region, issue, or historical context (e.g., \"How did the Ukraine war start?\" or \"What's the impact on developing countries?\"), I can dive deeper!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f47e0-83a0-49ca-a4bf-e4b3543ca865",
   "metadata": {},
   "source": [
    "## 2.3 Chat Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d904452b-83f5-44db-8c65-4f5f45348f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "class ChatSession:\n",
    "    def __init__(self, model:str, system:str = 'You are a helpful chatbot'):\n",
    "        self.model    = model\n",
    "        self.system   = system\n",
    "        self.messages = []\n",
    "\n",
    "        self.messages.append(dict(role='system', content=system))\n",
    "\n",
    "    def prompt(self, msg) -> str:\n",
    "        self.messages.append(dict(role='user', content=msg))\n",
    "        response = chat(model=self.model, messages=self.messages).message.content\n",
    "        self.messages.append(dict(role='assistant', content=response))\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f10b6afe-739f-48f6-99b6-097675dc1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChatSession(model='gemma2:2b', system='Please provide short and concise answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c356c25-914f-4731-8ac5-b5226b5ff0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are some gift ideas for your mom, depending on her interests:\n",
       "\n",
       "**Experiences:**\n",
       "\n",
       "* **Concert/Show tickets** \n",
       "* **Spa day**\n",
       "* **Cooking class** \n",
       "* **Weekend getaway**\n",
       "\n",
       "**Personal Gifts:**\n",
       "\n",
       "* **Personalized jewelry** (bracelet, necklace)\n",
       "* **Photo album or scrapbook** with memories\n",
       "* **Handmade gift basket** of her favorite treats\n",
       "* **Subscription box** for something she enjoys (books, coffee, beauty products)\n",
       "\n",
       "**Classic & Thoughtful:**\n",
       "\n",
       "* **Flowers and a card** \n",
       "* **Donations to her charity** in her name\n",
       "* **Homemade meal** she'll love\n",
       "\n",
       "\n",
       "Let me know what your mom likes and I can suggest more specific ideas! üòä \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(cs.prompt(\"I am thinking about a good gift for my mother\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b4dcc329-5a19-4ea1-acb6-0b558a35d9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To give better recommendations, tell me:\n",
       "\n",
       "1. **What kind of metals does she prefer (gold, silver, platinum)?**\n",
       "2. **Does she prefer simple or more intricate designs?**  (e.g., dainty chain necklace, bold statement ring) \n",
       "3. **Any particular gemstones she likes (emerald, diamond, etc.)?** \n",
       "4. **What's your budget range for the piece?**\n",
       "\n",
       "\n",
       "Once I have these details, I can give you more tailored suggestions! üòä  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(cs.prompt(\"I think she'd like a piece of jewelry. Do you have any recommendations?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0092b8ce-fef7-4459-855a-2e3e6c81d62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here is a suggestion within your budget:\n",
       "\n",
       "* **A beautiful sterling silver pendant with a birthstone or meaningful symbol engraved on it.** \n",
       "    * You could choose a crescent moon for peace/new beginnings, a heart for love, or an infinity symbol for eternity.  \n",
       "    * This combines style and personalization at an appealing price point.\n",
       "\n",
       "Let me know if you'd like to brainstorm further! üéÅ \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(cs.prompt(\"I have a budget of $200, can you just make a suggestion?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb247bf4-f6af-4550-9f4b-ee14c40ceae0",
   "metadata": {},
   "source": [
    "### Record of interaction\n",
    "\n",
    "Our `ChatSession` object has retained a record of the interaction in the `.messages` list attribute.\n",
    "\n",
    "Depending on your objectives you may need to be logging details of chat sessions, including:\n",
    "\n",
    "* model\n",
    "* input\n",
    "* output\n",
    "* performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2731e8b3-a745-41a4-ac5f-589f10781d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'Please provide short and concise answers'},\n",
       " {'role': 'user', 'content': 'I am thinking about a good gift for my mother'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Here are some gift ideas for your mom, depending on her interests:\\n\\n**Experiences:**\\n\\n* **Concert/Show tickets** \\n* **Spa day**\\n* **Cooking class** \\n* **Weekend getaway**\\n\\n**Personal Gifts:**\\n\\n* **Personalized jewelry** (bracelet, necklace)\\n* **Photo album or scrapbook** with memories\\n* **Handmade gift basket** of her favorite treats\\n* **Subscription box** for something she enjoys (books, coffee, beauty products)\\n\\n**Classic & Thoughtful:**\\n\\n* **Flowers and a card** \\n* **Donations to her charity** in her name\\n* **Homemade meal** she'll love\\n\\n\\nLet me know what your mom likes and I can suggest more specific ideas! üòä \\n\"},\n",
       " {'role': 'user',\n",
       "  'content': \"I think she'd like a piece of jewelry. Do you have any recommendations?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"To give better recommendations, tell me:\\n\\n1. **What kind of metals does she prefer (gold, silver, platinum)?**\\n2. **Does she prefer simple or more intricate designs?**  (e.g., dainty chain necklace, bold statement ring) \\n3. **Any particular gemstones she likes (emerald, diamond, etc.)?** \\n4. **What's your budget range for the piece?**\\n\\n\\nOnce I have these details, I can give you more tailored suggestions! üòä  \\n\"},\n",
       " {'role': 'user',\n",
       "  'content': 'I have a budget of $200, can you just make a suggestion?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Okay, here is a suggestion within your budget:\\n\\n* **A beautiful sterling silver pendant with a birthstone or meaningful symbol engraved on it.** \\n    * You could choose a crescent moon for peace/new beginnings, a heart for love, or an infinity symbol for eternity.  \\n    * This combines style and personalization at an appealing price point.\\n\\nLet me know if you'd like to brainstorm further! üéÅ \\n\"}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751340bf-6ef6-43ad-bf5d-fbdb00010ddd",
   "metadata": {},
   "source": [
    "### EXERCISE: Experiment with a chat session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c26c72-b64f-43a7-92c3-1839ee90b1b8",
   "metadata": {},
   "source": [
    "## 2.4 Creating Your Own Models\n",
    "\n",
    "Ollama provides a number of ways to create your own model, from any of these sources:\n",
    "\n",
    "* your local Ollama model repository\n",
    "* the global/public Ollama model repository\n",
    "* GGUF files you have locally\n",
    "\n",
    "This allows you to create model variants to meet your specific needs.  We'll experiment more with this later, but we can start with some basic examples of ephemeral models (i.e. ones that only exist in memory) which use *system prompts* as the basis for creating a model variant.\n",
    "\n",
    "More details on Ollama's `create` API can be found [here](https://github.com/ollama/ollama/blob/main/docs/api.md#create-a-model).\n",
    "\n",
    "### Note on Prompt Engineering\n",
    "\n",
    "Prompt engineering is a critical skill for successfully interacting with LLMs.  Details of how to do this well are out of scope for this tutorial, but as a minimum it is important to understand that *system prompts* provide a universal context for all chat messages within a session.  The model will always consider the system prompt when constructing a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9c02b6b-4ab3-4a3e-be63-4127e4b96f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.78 ms, sys: 6.29 ms, total: 9.08 ms\n",
      "Wall time: 87.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ollama.create(model='mario', from_='qwen3:4b', system=\"You are Mario from Super Mario Bros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d6baeb4-eb9b-4542-8465-5b48d140a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.88 ms, sys: 11.3 ms, total: 17.2 ms\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mario = ollama.generate(model='mario', prompt='What is on your mind today?')\n",
    "printmd(mario.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a52c29d-8f84-4e17-b3f2-aceffdb028c1",
   "metadata": {},
   "source": [
    "## 1.x Model and Response Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722fbd03-77b7-4977-9756-60003b106555",
   "metadata": {},
   "source": [
    "Let's take a quick look at the properties of an Ollama `model` object (this will help us in the next step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663fe3be-e652-4416-a005-1b19e8a295e2",
   "metadata": {},
   "source": [
    "**Tangent:** how do you investigate/discover properties of objects?\n",
    "\n",
    "* t...\n",
    "* d...\n",
    "* h...\n",
    "* g...\n",
    "* c..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21ca6884-f418-4575-befd-03f72b382dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "construct                     method\n",
      "copy                          method\n",
      "details                       ModelDetails\n",
      "dict                          method\n",
      "digest                        str\n",
      "from_orm                      method\n",
      "get                           method\n",
      "json                          method\n",
      "model                         str\n",
      "model_computed_fields         dict\n",
      "model_config                  dict\n",
      "model_construct               method\n",
      "model_copy                    method\n",
      "model_dump                    method\n",
      "model_dump_json               method\n",
      "model_extra                   NoneType\n",
      "model_fields                  dict\n",
      "model_fields_set              set\n",
      "model_json_schema             method\n",
      "model_parametrized_name       method\n",
      "model_post_init               method\n",
      "model_rebuild                 method\n",
      "model_validate                method\n",
      "model_validate_json           method\n",
      "model_validate_strings        method\n",
      "modified_at                   datetime\n",
      "parse_file                    method\n",
      "parse_obj                     method\n",
      "parse_raw                     method\n",
      "schema                        method\n",
      "schema_json                   method\n",
      "size                          ByteSize\n",
      "update_forward_refs           method\n",
      "validate                      method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/w88hbd6d14gfdjbk3j4lj_nc0000gn/T/ipykernel_42462/2218771710.py:5: PydanticDeprecatedSince211: Accessing the 'model_computed_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  print(f'{p:<30}{type(getattr(m,p)).__name__}')\n",
      "/var/folders/xb/w88hbd6d14gfdjbk3j4lj_nc0000gn/T/ipykernel_42462/2218771710.py:5: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  print(f'{p:<30}{type(getattr(m,p)).__name__}')\n"
     ]
    }
   ],
   "source": [
    "m_properties = set()\n",
    "for p in dir(m):\n",
    "    m_properties.add(p)\n",
    "    if not p.startswith('_'):\n",
    "        print(f'{p:<30}{type(getattr(m,p)).__name__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db6fb95-e349-43d3-9d05-6e6da40a008d",
   "metadata": {},
   "source": [
    "Repeat for `m.details`, only looking at the new properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6601c098-b3fa-4ec7-8125-49e0d18cee16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "families                      list\n",
      "family                        str\n",
      "format                        str\n",
      "parameter_size                str\n",
      "parent_model                  str\n",
      "quantization_level            str\n"
     ]
    }
   ],
   "source": [
    "for p in dir(m.details):\n",
    "    if not p.startswith('_') and not p in m_properties:\n",
    "        print(f'{p:<30}{type(getattr(m.details,p)).__name__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e47b20b-b0a9-4c45-86e1-94cc690d957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ollama._types.GenerateResponse"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed7fdfc5-0328-466a-a726-5885aa3dc13e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context                       list\n",
      "created_at                    str\n",
      "done                          bool\n",
      "done_reason                   str\n",
      "eval_count                    int\n",
      "eval_duration                 int\n",
      "load_duration                 int\n",
      "logprobs                      NoneType\n",
      "prompt_eval_count             int\n",
      "prompt_eval_duration          int\n",
      "response                      str\n",
      "thinking                      NoneType\n",
      "total_duration                int\n"
     ]
    }
   ],
   "source": [
    "for p in dir(response):\n",
    "    if not p.startswith('_') and not p in m_properties:\n",
    "        print(f'{p:<30}{type(getattr(response,p)).__name__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30605e85-cfaf-432b-8085-8ddfbae308bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
